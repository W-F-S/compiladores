--------------------------------------------------------------------------------------------------------------------------------------------------

main.py

from lexer import Lexer
from parser import Parser
from semantic import SemanticAnalyzer
from codegen import CodeGenerator

code = open("exemplo.txt").read()

lexer = Lexer(code)
tokens = lexer.tokenize()

parser = Parser(tokens)
ast = parser.parse()

semantic = SemanticAnalyzer(ast)
semantic.analyze()

generator = CodeGenerator(ast)
mips_code = generator.generate()

with open("saida.asm", "w") as f:
    f.write(mips_code)


--------------------------------------------------------------------------------------------------------------------------------------------------

parser.py

from lexer import Lexer

class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0
        self.ast = []

    def match(self, expected):
        if self.pos < len(self.tokens) and self.tokens[self.pos][0] == expected:
            self.pos += 1
        else:
            raise Exception(f"Erro sintático: esperado {expected}")

    def parse(self):
        while self.pos < len(self.tokens):
            if self.tokens[self.pos][0] == 'INT':
                self.parse_declaration()
            elif self.tokens[self.pos][0] == 'ID':
                self.parse_assignment()
            elif self.tokens[self.pos][0] == 'PRINT':
                self.parse_print()
            elif self.tokens[self.pos][0] == 'FUNCTION':
                self.parse_function()
            else:
                raise Exception("Erro sintático: comando desconhecido")
        return self.ast

    def parse_declaration(self):
        self.match('INT')
        var_name = self.tokens[self.pos][1]
        self.match('ID')
        self.match('SEMICOLON')
        self.ast.append(('declare', var_name))

    def parse_assignment(self):
        var_name = self.tokens[self.pos][1]
        self.match('ID')
        self.match('EQUALS')
        expr = self.parse_expression()
        self.match('SEMICOLON')
        self.ast.append(('assign', var_name, expr))

    def parse_print(self):
        self.match('PRINT')
        var_name = self.tokens[self.pos][1]
        self.match('ID')
        self.match('SEMICOLON')
        self.ast.append(('print', var_name))


    def parse_function(self):
        self.match('FUNCTION')
        func_name = self.tokens[self.pos][1]
        self.match('ID')
        self.match('LPAREN')
        args = []
        if self.tokens[self.pos][0] != 'RPAREN':
            while True:
                args.append(self.tokens[self.pos][1])
                self.match('ID')
                if self.tokens[self.pos][0] == 'COMMA':
                    self.match('COMMA')
                else:
                    break
        self.match('RPAREN')
        self.match('LBRACE')
        body = []
        while self.tokens[self.pos][0] != 'RETURN':
            if self.tokens[self.pos][0] == 'INT':
                body.append(self.parse_declaration())
            elif self.tokens[self.pos][0] == 'ID':
                body.append(self.parse_assignment())
            elif self.tokens[self.pos][0] == 'PRINT':
                body.append(self.parse_print())
        self.match('RETURN')
        ret_expr = self.parse_expression()
        self.match('SEMICOLON')
        self.match('RBRACE')
        self.ast.append(('function', func_name, args, body, ret_expr))

    def parse_expression(self):
        term = self.parse_term()
        while self.pos < len(self.tokens) and self.tokens[self.pos][0] in ('PLUS', 'MINUS'):
            op = self.tokens[self.pos][0]
            self.pos += 1
            next_term = self.parse_term()
            term = (op, term, next_term)
        return term

    def parse_term(self):
        if self.tokens[self.pos][0] == 'NUMBER':
            val = int(self.tokens[self.pos][1])
            self.pos += 1
            return ('num', val)
        elif self.tokens[self.pos][0] == 'ID':
            var_name = self.tokens[self.pos][1]
            self.pos += 1
            return ('var', var_name)
        else:
            raise Exception("Erro sintático: termo inválido")

--------------------------------------------------------------------------------------------------------------------------------------------------

semantic.py

class SemanticAnalyzer:
    def __init__(self, ast):
        self.ast = ast
        self.symbol_table = set()

    def analyze(self):
        for node in self.ast:
            if node[0] == 'declare':
                if node[1] in self.symbol_table:
                    raise Exception(f"Erro semântico: variável '{node[1]}' já declarada")
                self.symbol_table.add(node[1])
            elif node[0] == 'assign':
                if node[1] not in self.symbol_table:
                    raise Exception(f"Erro semântico: variável '{node[1]}' não declarada")
                self.check_expr(node[2])
            elif node[0] == 'print':
                if node[1] not in self.symbol_table:
                    raise Exception(f"Erro semântico: variável '{node[1]}' não declarada")
            elif node[0] == 'function':
                _, name, args, body, ret_expr = node
                local_symbols = set(args)
                for stmt in body:
                    if stmt[0] == 'declare':
                        if stmt[1] in local_symbols:
                            raise Exception(f"Erro semântico: variável '{stmt[1]}' já declarada")
                        local_symbols.add(stmt[1])
                    elif stmt[0] == 'assign':
                        if stmt[1] not in local_symbols:
                            raise Exception(f"Erro semântico: variável '{stmt[1]}' não declarada")
                        self.check_expr(stmt[2], local_symbols)
                    elif stmt[0] == 'print':
                        if stmt[1] not in local_symbols:
                            raise Exception(f"Erro semântico: variável '{stmt[1]}' não declarada")
                self.check_expr(ret_expr, local_symbols)


    def check_expr(self, expr):
        if expr[0] in ('PLUS', 'MINUS'):
            self.check_expr(expr[1])
            self.check_expr(expr[2])
        elif expr[0] == 'var' and expr[1] not in self.symbol_table:
            raise Exception(f"Erro semântico: variável '{expr[1]}' não declarada")

--------------------------------------------------------------------------------------------------------------------------------------------------

lexer.py

import re

TOKENS = [
    ('INT', r'int'),
    ('PRINT', r'print'),
    ('NUMBER', r'\d+'),
    ('ID', r'[a-zA-Z_]\w*'),
    ('PLUS', r'\+'),
    ('MINUS', r'-'),
    ('EQUALS', r'='),
    ('SEMICOLON', r';'),
    ('WHITESPACE', r'[ \t\n]+'),
    ('UNKNOWN', r'.'),
    ('FUNCTION', r'function'),
    ('RETURN', r'return'),
    ('LPAREN', r'\('),
    ('RPAREN', r'\)'),
    ('LBRACE', r'\{'),
    ('RBRACE', r'\}'),
    ('COMMA', r',')
]

class Lexer:
    def __init__(self, code):
        self.tokens = []
        self.code = code

    def tokenize(self):
        pos = 0
        while pos < len(self.code):
            match = None
            for token_type, token_regex in TOKENS:
                regex = re.compile(token_regex)
                match = regex.match(self.code, pos)
                if match:
                    if token_type != 'WHITESPACE':
                        token_value = match.group(0)
                        self.tokens.append((token_type, token_value))
                    pos = match.end(0)
                    break
            if not match:
                raise Exception(f'Erro léxico: símbolo desconhecido {self.code[pos]}')
        return self.tokens

--------------------------------------------------------------------------------------------------------------------------------------------------

codege.py

class CodeGenerator:
    def __init__(self, ast):
        self.ast = ast
        self.code = []
        self.var_map = {}

    def generate(self):
        self.code.append(".data")
        for node in self.ast:
            if node[0] == 'declare':
                var = node[1]
                self.var_map[var] = f"var_{var}"
                self.code.append(f"{self.var_map[var]}: .word 0")
        self.code.append(".text\n.globl main\nmain:")
        for node in self.ast:
            if node[0] == 'assign':
                self.gen_assign(node[1], node[2])
            elif node[0] == 'print':
                self.gen_print(node[1])
            elif node[0] == 'function':
                _, name, args, body, ret_expr = node
                self.code.append(f"{name}:")
                for stmt in body:
                    if stmt[0] == 'assign':
                        self.gen_assign(stmt[1], stmt[2])
                    elif stmt[0] == 'print':
                        self.gen_print(stmt[1])
                self.gen_expr(ret_expr)
                self.code.append("move $v0, $t0")
                self.code.append("jr $ra")
        self.code.append("li $v0, 10\nsyscall")
        return "\n".join(self.code)


    def gen_assign(self, var, expr):
        self.gen_expr(expr)
        self.code.append(f"sw $t0, {self.var_map[var]}")

    def gen_print(self, var):
        self.code.append(f"lw $a0, {self.var_map[var]}")
        self.code.append("li $v0, 1\nsyscall")

    def gen_expr(self, expr):
        if expr[0] == 'num':
            self.code.append(f"li $t0, {expr[1]}")
        elif expr[0] == 'var':
            self.code.append(f"lw $t0, {self.var_map[expr[1]]}")
        elif expr[0] in ('PLUS', 'MINUS'):
            self.gen_expr(expr[1])
            self.code.append("sw $t0, 0($sp)\naddi $sp, $sp, -4")
            self.gen_expr(expr[2])
            self.code.append("addi $sp, $sp, 4\nlw $t1, 0($sp)")
            op = 'add' if expr[0] == 'PLUS' else 'sub'
            self.code.append(f"{op} $t0, $t1, $t0")



I need to add support for functions. A defined function should get a argument list, an indefined list of instructions and finish with some return expression.
        As funções devem permitir uma lista de argumentos de entrada; uma quantidade indefinida de instruções; e terminar com alguma instrução de retorno de expressão.
